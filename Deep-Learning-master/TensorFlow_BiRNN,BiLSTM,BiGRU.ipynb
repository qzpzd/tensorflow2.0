{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用TensorFlow实现BiRNN/BiLSTM/BiGRU\n",
    "参考自 https://blog.csdn.net/u013230189/article/details/82807543 与 https://blog.csdn.net/mpk_no1/article/details/72875185\n",
    "\n",
    "在\"用TensorFlow实现RNN/LSTM/GRU\"的基础上进行改进：\n",
    "\n",
    "1：#定义RNN网络 def RNN\n",
    "\n",
    "2：weights定义的shape乘上2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "print(mnist.train.images.shape,mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape,mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rate=0.001  #学习速率\n",
    "train_step=1000  \n",
    "batch_size=1280    #每批样本数\n",
    "display_step=100   #控制输出频次\n",
    "\n",
    "frame_size=28     #序列里面每一个分量的大小。因为每个分量都是一行像素，而一行像素有28个像素点。所以frame_size为28\n",
    "sequence_length=28  #每个样本序列的长度。因为我们希望把一个28x28的图片当做一个序列输入到rnn进行训练，所以我们需要对图片进行序列化。一种最方便的方法就是我们认为行与行之间存在某些关系，于是把图片的每一行取出来当做序列的一个维度。所以这里sequence_size就是设置为28。\n",
    "hidden_num=100  #隐层个数\n",
    "n_classes=10  #类别数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step accuracy loss\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "100 0.814062 1.6571\n",
      "200 0.896094 1.56873\n",
      "300 0.917969 1.54532\n",
      "400 0.932031 1.53361\n",
      "500 0.941406 1.52362\n",
      "600 0.942969 1.52135\n",
      "700 0.946875 1.51494\n",
      "800 0.946094 1.51466\n",
      "900 0.957031 1.50404\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    #定义输入,输出\n",
    "    x=tf.placeholder(dtype=tf.float32,shape=[None,sequence_length*frame_size],name=\"inputx\")\n",
    "    y=tf.placeholder(dtype=tf.float32,shape=[None,n_classes],name=\"expected_y\")\n",
    "    #定义权值\n",
    "    weights=tf.Variable(tf.truncated_normal(shape=[hidden_num*2,n_classes]))\n",
    "    bias=tf.Variable(tf.zeros(shape=[n_classes]))\n",
    "\n",
    "    # 定义RNN网络\n",
    "    def RNN(x,weights,bias):\n",
    "        '''返回[batch_size,n_classes]'''\n",
    "        x=tf.reshape(x,shape=[-1,sequence_length,frame_size])\n",
    "        fw_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_num) # BiRNN/BiLSTM/BiGRU\n",
    "        bw_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_num)\n",
    "        \n",
    "        outputs,states=tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, x, dtype=tf.float32) # 输出(outputs, output_states),outputs为(output_fw, output_bw),states为(output_state_fw, output_state_bw)\n",
    "        output=tf.concat(outputs, 2)\n",
    "\n",
    "        return tf.nn.softmax(tf.matmul(output[:,-1,:],weights)+bias,1)\n",
    "\n",
    "    # 计算预计输出\n",
    "    predy=RNN(x,weights,bias)\n",
    "    # 定义损失函数和优化算法\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predy,labels=y))\n",
    "    train=tf.train.AdamOptimizer(train_rate).minimize(cost)\n",
    "    # 计算accuracy\n",
    "    correct_pred=tf.equal(tf.argmax(predy,1),tf.argmax(y,1))\n",
    "    accuracy=tf.reduce_mean(tf.to_float(correct_pred))\n",
    "\n",
    "\n",
    "## 开始训练\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    print('step','accuracy','loss')\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    step=1\n",
    "    testx,testy=mnist.test.next_batch(batch_size)\n",
    "    while step<train_step:\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "    #    batch_x=tf.reshape(batch_x,shape=[batch_size,sequence_length,frame_size])\n",
    "        _loss,__=sess.run([cost,train],feed_dict={x:batch_x,y:batch_y})\n",
    "        if step % display_step ==0:\n",
    "            acc,loss=sess.run([accuracy,cost],feed_dict={x:testx,y:testy})\n",
    "            print(step,acc,loss)\n",
    "\n",
    "        step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
